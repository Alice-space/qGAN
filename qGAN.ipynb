{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a Gauss distribution for clustering\n",
    "# mapping output of qNetwork to some distribution (measurement of probability)\n",
    "\n",
    "# Oh I need to read GAN, even try some diffusion tricks.\n",
    "# Target: make a Q-network to output a specific distribution? Why not Hamiltionian? \n",
    "\n",
    "# 1. make a bunch of data\n",
    "# 2. build a Q-network\n",
    "# 3. train the Q-network to output the distribution of the data using GAN\n",
    "# 4. test the Q-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generation of data\n",
    "\n",
    "NumData = 1000\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "np.random.seed(520309)\n",
    "\n",
    "# make a Dataloader\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class GaussDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.hists = []\n",
    "    for _ in range(NumData):\n",
    "      data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "      # Create histogram\n",
    "      hist, _ = np.histogram(data, bins=8)\n",
    "      # normalization\n",
    "      hist = hist / hist.sum()\n",
    "      self.hists.append(hist)\n",
    "  def __len__(self):\n",
    "    return len(self.hists)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.hists[idx]\n",
    "  \n",
    "dataset = GaussDataset()\n",
    "histdataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Plot histogram\n",
    "for i_batch, sample_batched in enumerate(histdataloader):\n",
    "  print(i_batch, sample_batched.size())\n",
    "  # for i in range(5):\n",
    "  #   plt.plot(sample_batched[-i], 'o-')\n",
    "  # plt.xlabel('Bins')\n",
    "  # plt.ylabel('Frequency')\n",
    "  # plt.title('Gaussian Distribution')\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister, QuantumCircuit\n",
    "from qiskit.circuit import QuantumCircuit, ParameterVector, Parameter\n",
    "\n",
    "qr = QuantumRegister(3, 'q')\n",
    "qc = QuantumCircuit(qr)\n",
    "\n",
    "# inputs = ParameterVector('inputs', 3)\n",
    "angles = ParameterVector('angles', 9)\n",
    "\n",
    "# qc.initialize(inputs[0], 0)\n",
    "\n",
    "# qc.ry(inputs[0], qr[0])\n",
    "# qc.ry(inputs[1], qr[1])\n",
    "# qc.ry(inputs[2], qr[2])\n",
    "\n",
    "# Layer 0\n",
    "qc.h(qr[0:3])\n",
    "qc.ry(angles[0], qr[0])\n",
    "qc.ry(angles[1], qr[1])\n",
    "qc.ry(angles[2], qr[2])\n",
    "\n",
    "# Layer 1\n",
    "\n",
    "qc.cx(qr[0], qr[1])\n",
    "qc.ry(angles[3], qr[0])\n",
    "qc.cx(qr[1], qr[2])\n",
    "qc.ry(angles[4], qr[1])\n",
    "qc.ry(angles[5], qr[2])\n",
    "\n",
    "# Layer 2\n",
    "qc.cx(qr[0], qr[1])\n",
    "qc.ry(angles[6], qr[0])\n",
    "qc.cx(qr[1], qr[2])\n",
    "qc.ry(angles[7], qr[1])\n",
    "qc.ry(angles[8], qr[2])\n",
    "\n",
    "# bind the parameters\n",
    "# qc = qc.bind_parameters({\n",
    "#   angles[0]: 0.5, angles[1]: 0.5, angles[2]: 0.5, angles[3]: 0.5, angles[4]: 0.5, angles[5]: 0.5, angles[6]: 0.5, angles[7]: 0.5, angles[8]: 0.5})\n",
    "\n",
    "# qc.measure_all()\n",
    "\n",
    "# qc.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a GAN discriminator\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.linear_input = nn.Linear(input_size, 20)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.linear20 = nn.Linear(20, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.linear_input(input)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.linear20(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# pytorch QNN\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "\n",
    "shots = 8192\n",
    "# GPU support\n",
    "# simulator_gpu = AerSimulator(method='statevector', device='GPU')\n",
    "# simulator_gpu.set_options(device='GPU')\n",
    "# qi = QuantumInstance(backend=simulator_gpu, shots=shots, seed_simulator=algorithm_globals.random_seed, seed_transpiler=algorithm_globals.random_seed)\n",
    "\n",
    "sampler = Sampler(options={\"shots\": shots, \"seed\": algorithm_globals.random_seed})\n",
    "\n",
    "# sampler = Sampler(options={\"shots\": shots, \"seed\": algorithm_globals.random_seed, \"backend\": qi.backend})\n",
    "\n",
    "def create_generator() -> TorchConnector:\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        sampler=sampler,\n",
    "        input_params=[],\n",
    "        weight_params=qc.parameters,\n",
    "        sparse=False,\n",
    "    )\n",
    "\n",
    "    initial_weights = algorithm_globals.random.random(qc.num_parameters)\n",
    "    return TorchConnector(qnn, initial_weights)\n",
    "\n",
    "\n",
    "generator = create_generator()\n",
    "discriminator = Discriminator(8)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "lr = 0.0002  # learning rate\n",
    "b1 = 0.5  # first momentum parameter\n",
    "b2 = 0.999  # second momentum parameter\n",
    "\n",
    "generator_optimizer = Adam(generator.parameters(), lr=lr, betas=(b1, b2), weight_decay=0.005)\n",
    "discriminator_optimizer = Adam(\n",
    "    discriminator.parameters(), lr=lr, betas=(b1, b2), weight_decay=0.005\n",
    ")\n",
    "\n",
    "# gen_dist = generator(torch.tensor([[] for _ in range(batch_size)]))\n",
    "# print(gen_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.stats import entropy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "start = time.time()\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    generator_loss_values = []\n",
    "    discriminator_loss_values = []\n",
    "    entropy_values = []\n",
    "    for i_batch, sample_batched in enumerate(histdataloader):\n",
    "        # print(i_batch, sample_batched.size())\n",
    "        # update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        # print(sample_batched.shape[0])\n",
    "        ## train with real\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        real_dist = torch.tensor(sample_batched, dtype=torch.float)\n",
    "        discriminat_real_dist = discriminator(real_dist)\n",
    "        # print(\"real\", real_dist.shape, discriminat_real_dist.shape)\n",
    "        real_loss = criterion(discriminat_real_dist, torch.ones(sample_batched.shape[0], 1))\n",
    "        real_loss.backward()\n",
    "\n",
    "        ## train with fake\n",
    "        gen_dist = generator(torch.tensor([[] for _ in range(sample_batched.shape[0])]))\n",
    "        discriminat_gen_dist = discriminator(gen_dist.detach())\n",
    "        # print(\"gen\", gen_dist.shape, discriminat_gen_dist.shape)\n",
    "        fake_loss = criterion(discriminat_gen_dist, torch.zeros(sample_batched.shape[0], 1))\n",
    "        fake_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # update G network: maximize log(D(G(z)))\n",
    "        generator_optimizer.zero_grad()\n",
    "        # print(discriminator(gen_dist))\n",
    "        generator_loss = criterion(discriminator(gen_dist), torch.ones(sample_batched.shape[0], 1))\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # relative entropy\n",
    "        mean_entropy = entropy(real_dist, gen_dist.detach()).mean()\n",
    "\n",
    "        if np.isnan(mean_entropy) or np.isinf(mean_entropy):\n",
    "            print(f\"Epoch {epoch}, Batch {i_batch}, D Loss: {real_loss + fake_loss}, G Loss: {generator_loss}, Entropy: {entropy(real_dist, gen_dist.detach()).mean()}, real: {real_dist}, gen: {gen_dist}\")\n",
    "\n",
    "        generator_loss_values.append(generator_loss.detach().item())\n",
    "        discriminator_loss_values.append(real_loss.detach() + fake_loss.detach())\n",
    "        entropy_values.append(mean_entropy)\n",
    "        \n",
    "    writer.add_scalar('Loss/DLoss', np.mean(discriminator_loss_values), epoch)\n",
    "    writer.add_scalar('Loss/GLoss', np.mean(generator_loss_values), epoch)\n",
    "    writer.add_scalar('Entropy', np.mean(entropy_values), epoch)\n",
    "\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Fit in {elapsed:0.2f} sec\")\n",
    "\n",
    "# plot the result, hist graph for real_dist and line dot for gen_dist\n",
    "# real_dist, gen_dist\n",
    "# plt.bar(bins[:-1], real_dist.detach().numpy(), width=(bins[1]-bins[0]))\n",
    "# plt.plot(bins[:-1], gen_dist.detach().numpy(), 'r')\n",
    "# plt.show()\n",
    "# plt.bar(bins[:-1], real_dist.detach().numpy(), width=(bins[1]-bins[0]))\n",
    "# plt.bar(bins[:-1], gen_dist.detach().numpy(), width=(bins[1]-bins[0]))\n",
    "# plt.show()\n",
    "# print(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why we design the circuit in this way?\n",
    "\n",
    "# superposition + parameter ?\n",
    "\n",
    "# How to back propagate the parameter?\n",
    "\n",
    "# How to use the quantum feature to detect the minimum of the function?\n",
    "\n",
    "# 哥德尔编码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
